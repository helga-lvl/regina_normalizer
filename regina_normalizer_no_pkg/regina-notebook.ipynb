{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import time\n",
    "from tokenizer import split_into_sentences\n",
    "import pos\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/starspace/.cache/torch/hub/cadia-lvl_POS_master\n"
     ]
    }
   ],
   "source": [
    "import abbr_functions as af\n",
    "import number_help as nh\n",
    "import number_functions as nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abbr_dict as abb_dict\n",
    "import area_dict as are_dict\n",
    "import currency_dict as curr_dict\n",
    "import denominator_dict as den_dict\n",
    "import direction_dict as dir_dict\n",
    "import distance_dict as dist_dict\n",
    "import electronic_dict as el_dict\n",
    "import period_dict as per_dict\n",
    "import rest_dict as r_dict\n",
    "import time_dict as t_dict\n",
    "import volume_dict as vol_dict\n",
    "import weight_dict as w_dict\n",
    "import pre_help_dicts as pre_dicts\n",
    "import symbols_dict as symb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cardinal_ones_tuples as cot\n",
    "import cardinal_thousands_tuples as ctt\n",
    "import cardinal_million_tuples as cmt\n",
    "import cardinal_big_tuples as cbt\n",
    "import ordinal_ones_tuples as oot\n",
    "import ordinal_thousands_tuples as ott\n",
    "import ordinal_million_tuples as omt\n",
    "import ordinal_big_tuples as obt\n",
    "import decimal_thousands_tuples as dtt\n",
    "import fraction_tuples as ft\n",
    "import sport_tuples as st\n",
    "import time_tuples as tt\n",
    "import abbr_functions as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tuple_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import number_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_help_dict = pre_dicts.pre_help_dicts\n",
    "abbr_dict = abb_dict.abbr_dict\n",
    "area_dict = are_dict.make_area_dict()\n",
    "currency_dict = curr_dict.make_currency_dict()\n",
    "denominator_dict = den_dict.denominator_dict\n",
    "direction_dict = dir_dict.direction_dict\n",
    "distance_dict = dist_dict.make_distance_dict()\n",
    "electronic_dict = el_dict.make_electronic_dict()\n",
    "period_dict = per_dict.make_period_dict()\n",
    "rest_dict = r_dict.make_rest_measure_dict()\n",
    "time_dict = t_dict.make_time_dict()\n",
    "volume_dict = vol_dict.make_volume_dict()\n",
    "weight_dict = w_dict.make_weight_dict()\n",
    "symb_dict = symb_dict.symb_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardinal_thousand_tuples = cot.cardinal_ones_tuples + ctt.cardinal_thousands_tuples\n",
    "cardinal_million_tuples = cardinal_thousand_tuples + cmt.cardinal_million_tuples\n",
    "cardinal_big_tuples = cardinal_million_tuples + cbt.cardinal_big_tuples\n",
    "\n",
    "ordinal_thousand_tuples = oot.ordinal_ones_tuples + ott.ordinal_thousands_tuples + ctt.cardinal_thousands_tuples\n",
    "ordinal_million_tuples = ordinal_thousand_tuples + cmt.cardinal_million_tuples + omt.ordinal_million_tuples\n",
    "ordinal_big_tuples = ordinal_million_tuples + cbt.cardinal_big_tuples + obt.ordinal_big_tuples\n",
    "\n",
    "decimal_thousand_tuples = cardinal_thousand_tuples + dtt.decimal_thousands_tuples\n",
    "\n",
    "decimal_big_tuples = cardinal_big_tuples + dtt.decimal_thousands_tuples\n",
    "\n",
    "fraction_tuples = cardinal_thousand_tuples + ft.fraction_tuples\n",
    "\n",
    "sport_tuples = st.sport_tuples\n",
    "\n",
    "time_tuples = tt.time_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN\n",
    "\n",
    "```\n",
    "    input_file = a file with text that needs to be normalized\n",
    "    output_file = a file with the normalized text\n",
    "    domain = can be 'sport' or 'other'  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(text_string, domain):\n",
    "    sent_grein = list(split_into_sentences(text_string))  \n",
    "    for sent in sent_grein:\n",
    "        abbr_sent = af.replace_abbreviations(sent, domain)\n",
    "        no_sent = nf.handle_sentence(abbr_sent, domain)\n",
    "        print(no_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leikurinn fór  þrjú  tvö . \n",
      "Palli skoraði  tvö mörk . \n",
      "Jón lagði upp  eitt þeirra . \n"
     ]
    }
   ],
   "source": [
    "los = \"Leikurinn fór 3-2. Palli skoraði 2 mörk. Jón lagði upp 1 þeirra.\"\n",
    "normalize_string(los, 'sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_file(input_file, output_file, domain):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "    sent_grein = list(split_into_sentences(lines))  \n",
    "    sent_expand = []\n",
    "    for sent in sent_grein:\n",
    "        abbr_sent = af.replace_abbreviations(sent, domain)\n",
    "        no_sent = nf.handle_sentence(abbr_sent, domain)\n",
    "        sent_expand.append(no_sent)\n",
    "    with open(output_file, 'w') as f:\n",
    "        for item in sent_expand:\n",
    "            f.write(\"%s\\n\" % item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you have to have an input file to normalize\n",
    "normalize('input.txt', 'output.txt', 'other')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
